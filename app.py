"""
LangGraph Chatbot PoC with Model Comparison
Compares Qwen3 and DeepSeek 3.2 via OpenRouter API
"""

from typing import TypedDict, List, Literal
import os
import sqlite3
import json
import requests
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from real_estate_db import create_real_estate_db

# Get absolute path to database file
DB_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "real_estate_data.db")

# Load environment variables
load_dotenv()

# =======================
# 1. STATE DEFINITION
# =======================

class AgentState(TypedDict):
    """The shared memory of the graph"""
    question: str                # The User Query
    chat_history: List[dict]     # Past conversation (User: ..., AI: ...)
    query_type: str              # Router output: "factual", "semantic", "data"
    sql_query: str               # The SQL generated by the LLM
    sql_result: str              # The raw data retrieved from Query DB
    final_answer: str            # The final plain English response
    error: str                   # Tracks if SQL execution failed (for retries)
    retry_count: int             # Number of SQL retries
    model_name: str              # Which model is being used


# =======================
# 2. SYSTEM PROMPTS
# =======================

ROUTER_SYSTEM_PROMPT = """You classify queries for a real estate database chatbot.

ONLY TWO OPTIONS:

1. "general" - ONLY for greetings: "hello", "hi", "hey", "bye", "thank you", "thanks"

2. "data" - EVERYTHING ELSE (default)

If the question mentions: projects, properties, apartments, units, BHK, prices, builders, amenities, locations, construction, or ANYTHING real estate related ‚Üí MUST be "data"

If you're unsure ‚Üí classify as "data"

Respond with ONLY ONE WORD: data OR general"""

SQL_GENERATOR_SYSTEM_PROMPT = """You are an expert SQL query generator specializing in SQLite.

Your task is to convert natural language questions into valid SQLite queries.

RULES:
1. Generate ONLY the SQL query - no explanations, no markdown, no code blocks
2. Use proper SQLite syntax
3. Always use table and column names exactly as provided in the schema
4. For counting queries, use COUNT(*)
5. For filtering, use WHERE clauses appropriately
6. If you receive an error, analyze it carefully and fix the issue

IMPORTANT: Output ONLY the SQL query, nothing else."""

RESPONSE_SYSTEM_PROMPT = """You are a helpful and friendly assistant.

Your task is to convert database query results into clear, natural language responses.

RULES:
1. Be conversational and friendly
2. Format numbers and data clearly
3. If results are empty, say "I couldn't find any matching records"
4. For multiple results, summarize them concisely
5. Don't include technical SQL details unless asked
6. Be accurate - only state what the data shows

Keep responses clear, concise, and user-friendly."""

GENERAL_CONVERSATION_PROMPT = """You are a friendly assistant for a real estate database chatbot.

Respond ONLY to greetings like "hello", "hi", "thank you", "bye".

For ANY real estate questions, say: "Let me check the database for you."

Be brief and warm."""

# =======================
# 3. OPENROUTER LLM CLIENT
# =======================

class OpenRouterLLM:
    """OpenRouter API client with error handling"""

    def __init__(self, model_name: str, api_key: str = None):
        self.model_name = model_name
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"

    def invoke(self, prompt: str, system_prompt: str = None) -> str:
        """Call the OpenRouter API with error handling"""
        try:
            messages = []

            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})

            messages.append({"role": "user", "content": prompt})

            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            payload = {
                "model": self.model_name,
                "messages": messages,
                "temperature": 0.3  # Lower temperature for more consistent outputs
            }

            response = requests.post(
                self.base_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()

            result = response.json()
            return result["choices"][0]["message"]["content"]

        except requests.exceptions.Timeout:
            raise Exception("API request timed out. Please try again.")
        except requests.exceptions.ConnectionError:
            raise Exception("Unable to connect to the API. Please check your internet connection.")
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 401:
                raise Exception("Invalid API key. Please check your OPENROUTER_API_KEY.")
            elif e.response.status_code == 429:
                raise Exception("Rate limit exceeded. Please try again in a moment.")
            else:
                raise Exception(f"API error: {str(e)}")
        except KeyError:
            raise Exception("Unexpected API response format.")
        except Exception as e:
            raise Exception(f"Unexpected error: {str(e)}")


# =======================
# 4. DATABASE SETUP
# =======================

def get_database_schema():
    """Get the database schema for SQL generation - only creates DB if it doesn't exist"""
    # Only create database if it doesn't exist
    if not os.path.exists(DB_PATH):
        print("üìÅ Database not found, creating...")
        schema_text = create_real_estate_db()
        return schema_text

    # Return complete schema for existing database
    return """
DATABASE: real_estate_data.db

TABLE: projects
Columns:
- project_id (TEXT PRIMARY KEY)
- tenant_id (TEXT NOT NULL)
- project_name (TEXT NOT NULL) - Name of the real estate project
- developer_name (TEXT NOT NULL) - Builder/developer name
- city (TEXT NOT NULL)
- description (TEXT)
- total_project_area_acres (DECIMAL)
- open_space_percentage (DECIMAL)
- number_of_towers (INTEGER)
- total_units_count (INTEGER)
- tower_structure_details (TEXT)
- is_block_wing_structure (BOOLEAN)
- rera_registration_number (TEXT)
- approval_body (TEXT)
- launch_date, sales_launch_date, construction_start_date (DATE)
- rera_possession_date, estimated_possession_date (DATE)
- construction_status (VARCHAR) - Values: 'Under Construction', 'Completed', 'Ready to Move'
- completion_percentage (DECIMAL)
- construction_technology (TEXT)
- stamp_duty_percentage, registration_charges_percentage (DECIMAL)
- construction_partners (TEXT)
- amenities, payment_plans, unique_selling_propositions (TEXT - JSON)
- schools, colleges, hospitals, it_parks_companies (TEXT)
- nearby_top_places, shopping_malls, health_fitness (TEXT)
- connecting_roads, metro_stations, bus_stands, airport_distance (TEXT)
- created_at, modified_at (TIMESTAMP)

TABLE: project_units
Columns:
- unit_id (TEXT PRIMARY KEY)
- project_id (TEXT - FOREIGN KEY to projects.project_id)
- tenant_id (TEXT NOT NULL)
- configuration_type (VARCHAR) - Examples: '2BHK', '3BHK', '4BHK', 'Villa'
- property_type (VARCHAR) - Examples: 'Apartment', 'Villa', 'Penthouse'
- built_up_area_sqft (DECIMAL)
- carpet_area_sqft (DECIMAL)
- base_price (DECIMAL) - Price in currency
- current_average_psf (DECIMAL) - Price per square foot
- market_psf (DECIMAL)
- view_premium_details, high_floor_premium_details, corner_unit_premium_details (TEXT)
- last_price_revision_date, next_planned_revision_date (DATE)
- last_price_change_percentage (DECIMAL)
- current_festive_offers (TEXT)
- created_at (TIMESTAMP)

IMPORTANT SQL GUIDELINES:
- Use JOIN to combine project and unit information
- For project queries: SELECT * FROM projects WHERE ...
- For unit queries: SELECT * FROM project_units WHERE ...
- For combined queries: SELECT p.project_name, u.* FROM projects p JOIN project_units u ON p.project_id = u.project_id WHERE ...
- Configuration type pattern matching: WHERE configuration_type LIKE '%3BHK%'
- Count projects: SELECT COUNT(*) FROM projects
- Count units: SELECT COUNT(*) FROM project_units
"""


# =======================
# 5. GRAPH NODES
# =======================

def router_node(state: AgentState) -> dict:
    """
    Node A: The Router
    Analyzes the question + chat_history to classify intent
    """
    print(f"[{state['model_name']}] üß≠ Router analyzing question...")

    try:
        llm = OpenRouterLLM(state['model_name'])

        # Format chat history
        history_str = "\n".join([
            f"{msg['role']}: {msg['content']}"
            for msg in state.get('chat_history', [])[-3:]  # Last 3 messages
        ])

        prompt = f"""
Recent conversation:
{history_str if history_str else "None"}

Current question: {state['question']}

Classification:"""

        classification = llm.invoke(prompt, ROUTER_SYSTEM_PROMPT).strip().lower()

        # Extract just the classification word - default to "data" for everything except greetings
        if "general" in classification:
            query_type = "general"
        else:
            # Force everything else to be a data query
            query_type = "data"

        print(f"[{state['model_name']}] ‚úÖ Classified as: {query_type}")

        return {"query_type": query_type}

    except Exception as e:
        print(f"[{state['model_name']}] ‚ùå Router error: {str(e)}")
        # Default to DATA query on error (not general)
        return {
            "query_type": "data",
            "sql_query": "",
            "sql_result": "",
            "error": f"Router error: {str(e)}"
        }


def sql_gen_node(state: AgentState) -> dict:
    """
    Node B: SQL Generator
    Generates SQL query based on the question
    """
    print(f"[{state['model_name']}] üîß Generating SQL query...")

    try:
        llm = OpenRouterLLM(state['model_name'])

        schema = get_database_schema()

        # Enhanced system prompt with schema
        system_prompt_with_schema = f"""{SQL_GENERATOR_SYSTEM_PROMPT}

DATABASE SCHEMA:
{schema}"""

        # Build prompt with error feedback if this is a retry
        if state.get('error') and state.get('retry_count', 0) > 0:
            prompt = f"""User question: {state['question']}

Previous SQL attempt: {state.get('sql_query')}
Error received: {state.get('error')}

Please fix the SQL query based on the error above.

SQL query:"""
        else:
            prompt = f"""User question: {state['question']}

SQL query:"""

        sql_query = llm.invoke(prompt, system_prompt_with_schema).strip()

        # Clean up the SQL (remove markdown if present)
        sql_query = sql_query.replace("```sql", "").replace("```", "").strip()
        # Remove any remaining backticks
        sql_query = sql_query.replace("`", "")

        print(f"[{state['model_name']}] üìù Generated SQL: {sql_query}")

        return {
            "sql_query": sql_query,
            "sql_result": "",  # Clear previous results
            "error": ""  # Clear previous errors
        }

    except Exception as e:
        print(f"[{state['model_name']}] ‚ùå SQL Generation error: {str(e)}")
        return {
            "sql_query": "",  # Clear failed query
            "sql_result": "",  # Clear any old results
            "error": f"SQL generation failed: {str(e)}",
            "retry_count": state.get('retry_count', 0) + 1
        }


def execute_sql_node(state: AgentState) -> dict:
    """
    Node C: Query DB
    Executes the SQL query and handles errors
    """
    print(f"[{state['model_name']}] üóÑÔ∏è  Executing SQL...")

    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute(state['sql_query'])
        results = cursor.fetchall()
        conn.close()

        sql_result = json.dumps(results)
        print(f"[{state['model_name']}] ‚úÖ Query successful: {len(results)} rows")

        return {
            "sql_result": sql_result,
            "sql_query": state['sql_query'],  # Preserve the successful query
            "error": "",
            "retry_count": 0
        }

    except Exception as e:
        error_msg = str(e)
        retry_count = state.get('retry_count', 0) + 1
        print(f"[{state['model_name']}] ‚ùå SQL Error (attempt {retry_count}): {error_msg}")

        return {
            "sql_result": "",  # Clear results on error
            "sql_query": state.get('sql_query', ''),  # Preserve query for retry
            "error": error_msg,
            "retry_count": retry_count
        }


def response_node(state: AgentState) -> dict:
    """
    Node D: Response Synthesizer
    Generates the final natural language response
    """
    print(f"[{state['model_name']}] üí¨ Generating final response...")

    try:
        # Check if there were persistent errors
        if state.get('error') and state.get('retry_count', 0) >= 2:
            # Maximum retries exceeded - provide user-friendly error message
            return {
                "final_answer": "I apologize, but I'm having trouble processing your data query at the moment. "
                               "This could be due to the complexity of the question or a temporary issue. "
                               "Please try rephrasing your question or try again in a moment."
            }

        llm = OpenRouterLLM(state['model_name'])

        if state['query_type'] == 'data':
            # Validate we have both sql_query and sql_result
            sql_query = state.get('sql_query', '').strip()
            sql_result = state.get('sql_result', '').strip()

            if not sql_query or not sql_result:
                return {
                    "final_answer": "I couldn't retrieve the data you requested. "
                                   "There was an issue generating or executing the database query. "
                                   "Please try rephrasing your question or ask something else."
                }

            prompt = f"""User question: {state['question']}

SQL Query executed: {sql_query}
Results: {sql_result}

Provide a clear, concise answer:"""

            final_answer = llm.invoke(prompt, RESPONSE_SYSTEM_PROMPT)

        else:
            # General conversation (greetings only)
            final_answer = llm.invoke(state['question'], GENERAL_CONVERSATION_PROMPT)

        print(f"[{state['model_name']}] ‚úÖ Response generated")

        return {"final_answer": final_answer}

    except Exception as e:
        print(f"[{state['model_name']}] ‚ùå Response generation error: {str(e)}")
        # Fallback response for any errors
        return {
            "final_answer": "I apologize, but I'm unable to generate a response right now. "
                           "This might be a temporary issue. Please try again in a moment."
        }


# =======================
# 6. CONDITIONAL LOGIC
# =======================

def route_query(state: AgentState) -> Literal["sql_gen", "response"]:
    """Determines where to go after the router"""
    if state['query_type'] == 'data':
        return "sql_gen"
    else:
        return "response"


def check_sql_error(state: AgentState) -> Literal["sql_gen", "response"]:
    """Determines if we need to retry SQL generation"""
    if state.get('error') and state.get('retry_count', 0) < 2:
        # Retry SQL generation (max 2 retries)
        return "sql_gen"
    else:
        return "response"


# =======================
# 7. GRAPH CONSTRUCTION
# =======================

def create_graph(model_name: str) -> StateGraph:
    """Creates the LangGraph workflow"""

    workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("router", router_node)
    workflow.add_node("sql_gen", sql_gen_node)
    workflow.add_node("execute_sql", execute_sql_node)
    workflow.add_node("response", response_node)

    # Set entry point
    workflow.set_entry_point("router")

    # Add conditional edge from router
    workflow.add_conditional_edges(
        "router",
        route_query,
        {
            "sql_gen": "sql_gen",
            "response": "response"
        }
    )

    # Add edge from SQL gen to execution
    workflow.add_edge("sql_gen", "execute_sql")

    # Add conditional edge for error handling (cyclic!)
    workflow.add_conditional_edges(
        "execute_sql",
        check_sql_error,
        {
            "sql_gen": "sql_gen",  # Retry SQL generation
            "response": "response"  # Move to response
        }
    )

    # Add edge from response to end
    workflow.add_edge("response", END)

    return workflow.compile()


# =======================
# 8. MODEL COMPARISON
# =======================

def compare_models(question: str, chat_history: List[dict] = None):
    """Compare responses from both models with error handling"""

    models = {
        "Qwen 2.5": "qwen/qwen-2.5-72b-instruct",
        "DeepSeek V3": "deepseek/deepseek-chat"
    }

    chat_history = chat_history or []

    print("\n" + "="*70)
    print(f"QUESTION: {question}")
    print("="*70 + "\n")

    results = {}

    for model_display_name, model_id in models.items():
        print(f"\n{'‚îÄ'*70}")
        print(f"ü§ñ Testing with {model_display_name}")
        print(f"{'‚îÄ'*70}\n")

        try:
            # Create graph for this model
            graph = create_graph(model_id)

            # Initial state
            initial_state = {
                "question": question,
                "chat_history": chat_history,
                "query_type": "",
                "sql_query": "",
                "sql_result": "",
                "final_answer": "",
                "error": "",
                "retry_count": 0,
                "model_name": model_id
            }

            # Run the graph
            final_state = graph.invoke(initial_state)

            results[model_display_name] = {
                "query_type": final_state['query_type'],
                "sql_query": final_state.get('sql_query', 'N/A'),
                "final_answer": final_state['final_answer'],
                "error": final_state.get('error', ''),
                "success": True
            }

            print(f"\n‚ú® {model_display_name} Response:")
            print(f"{final_state['final_answer']}\n")

        except Exception as e:
            error_msg = str(e)
            print(f"\n‚ùå {model_display_name} Error: {error_msg}\n")

            results[model_display_name] = {
                "query_type": "error",
                "sql_query": "N/A",
                "final_answer": f"Error: {error_msg}",
                "error": error_msg,
                "success": False
            }

    # Print comparison summary
    print("\n" + "="*70)
    print("üìä COMPARISON SUMMARY")
    print("="*70 + "\n")

    for model_name, result in results.items():
        status = "‚úÖ Success" if result.get('success') else "‚ùå Failed"
        print(f"{model_name}: {status}")
        print(f"  Query Type: {result['query_type']}")
        if result['query_type'] == 'data' and result.get('success'):
            print(f"  SQL: {result['sql_query']}")
        print(f"  Answer: {result['final_answer'][:100]}...")
        if result.get('error'):
            print(f"  Error: {result['error'][:100]}...")
        print()

    return results


# =======================
# 9. EXAMPLE USAGE
# =======================

if __name__ == "__main__":
    # Setup database
    print("üèóÔ∏è  Setting up Real Estate database...")
    schema = create_real_estate_db()
    print("‚úÖ Database ready!\n")

    # Test questions for real estate data
    test_questions = [
        "How many projects are under construction?",
        "Which projects have more than 75% open space?",
        "What is the cheapest 2BHK apartment available?",
        "Show me all 3BHK units with their prices",
        "Which units have festive offers right now?",
        "What is the average price per sqft for villas?",
        "List all projects by Prestige Group with their unit types",
        "Show me projects near the airport with pricing details"
    ]

    # Run comparison for each question
    for question in test_questions:
        compare_models(question)
        print("\n" + "="*70 + "\n")
