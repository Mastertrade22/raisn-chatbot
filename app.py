"""
LangGraph Chatbot PoC with Model Comparison
Compares Qwen3 and DeepSeek 3.2 via OpenRouter API
"""

from typing import TypedDict, List, Literal
import os
import sqlite3
import json
import requests
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from real_estate_db import create_real_estate_db

# Load environment variables
load_dotenv()

# =======================
# 1. STATE DEFINITION
# =======================

class AgentState(TypedDict):
    """The shared memory of the graph"""
    question: str                # The User Query
    chat_history: List[dict]     # Past conversation (User: ..., AI: ...)
    query_type: str              # Router output: "factual", "semantic", "data"
    sql_query: str               # The SQL generated by the LLM
    sql_result: str              # The raw data retrieved from Query DB
    final_answer: str            # The final plain English response
    error: str                   # Tracks if SQL execution failed (for retries)
    retry_count: int             # Number of SQL retries
    model_name: str              # Which model is being used


# =======================
# 2. SYSTEM PROMPTS
# =======================

ROUTER_SYSTEM_PROMPT = """You are an intelligent query classifier for a REAL ESTATE DATABASE chatbot system.

Your task is to analyze user questions and classify them into ONE of these categories:

1. "data" - Questions that require querying the REAL ESTATE database
   Examples:
   - "How many projects are under construction?"
   - "Show me all 3BHK apartments"
   - "What is the cheapest 2BHK available?"
   - "Which projects have swimming pools?"
   - "List all projects by Prestige Group"
   - "What are the prices for villas?"
   - "Show me projects near the airport"
   - "Which units have festive offers?"
   - ANY question about: projects, units, apartments, prices, amenities, builders, locations, specifications

2. "general" - General conversation or greetings ONLY
   Examples:
   - "Hello", "Hi", "Hey"
   - "How are you?"
   - "Thank you", "Thanks"
   - "Goodbye", "Bye"

3. "factual" - General knowledge questions NOT about real estate
   Examples:
   - "What is Python?"
   - "Explain machine learning"
   - "What is the capital of France?"

IMPORTANT:
- If the question is about real estate, properties, projects, apartments, houses, prices, or anything related to real estate ‚Üí classify as "data"
- Respond with ONLY ONE WORD: data, general, or factual
- No explanations, no punctuation, just the category."""

SQL_GENERATOR_SYSTEM_PROMPT = """You are an expert SQL query generator specializing in SQLite.

Your task is to convert natural language questions into valid SQLite queries.

RULES:
1. Generate ONLY the SQL query - no explanations, no markdown, no code blocks
2. Use proper SQLite syntax
3. Always use table and column names exactly as provided in the schema
4. For counting queries, use COUNT(*)
5. For filtering, use WHERE clauses appropriately
6. If you receive an error, analyze it carefully and fix the issue

IMPORTANT: Output ONLY the SQL query, nothing else."""

RESPONSE_SYSTEM_PROMPT = """You are a helpful and friendly assistant.

Your task is to convert database query results into clear, natural language responses.

RULES:
1. Be conversational and friendly
2. Format numbers and data clearly
3. If results are empty, say "I couldn't find any matching records"
4. For multiple results, summarize them concisely
5. Don't include technical SQL details unless asked
6. Be accurate - only state what the data shows

Keep responses clear, concise, and user-friendly."""

GENERAL_CONVERSATION_PROMPT = """You are a friendly, helpful assistant integrated into a database chatbot.

Your task is to respond naturally to general conversation and greetings.

RULES:
1. Be warm and professional
2. Keep responses brief and friendly
3. You can mention you're a database assistant if relevant
4. Don't make up information

Be natural and conversational."""

# =======================
# 3. OPENROUTER LLM CLIENT
# =======================

class OpenRouterLLM:
    """OpenRouter API client with error handling"""

    def __init__(self, model_name: str, api_key: str = None):
        self.model_name = model_name
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"

    def invoke(self, prompt: str, system_prompt: str = None) -> str:
        """Call the OpenRouter API with error handling"""
        try:
            messages = []

            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})

            messages.append({"role": "user", "content": prompt})

            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            payload = {
                "model": self.model_name,
                "messages": messages,
                "temperature": 0.3  # Lower temperature for more consistent outputs
            }

            response = requests.post(
                self.base_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()

            result = response.json()
            return result["choices"][0]["message"]["content"]

        except requests.exceptions.Timeout:
            raise Exception("API request timed out. Please try again.")
        except requests.exceptions.ConnectionError:
            raise Exception("Unable to connect to the API. Please check your internet connection.")
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 401:
                raise Exception("Invalid API key. Please check your OPENROUTER_API_KEY.")
            elif e.response.status_code == 429:
                raise Exception("Rate limit exceeded. Please try again in a moment.")
            else:
                raise Exception(f"API error: {str(e)}")
        except KeyError:
            raise Exception("Unexpected API response format.")
        except Exception as e:
            raise Exception(f"Unexpected error: {str(e)}")


# =======================
# 4. DATABASE SETUP
# =======================

def get_database_schema():
    """Get the database schema for SQL generation"""
    return create_real_estate_db()


# =======================
# 5. GRAPH NODES
# =======================

def router_node(state: AgentState) -> dict:
    """
    Node A: The Router
    Analyzes the question + chat_history to classify intent
    """
    print(f"[{state['model_name']}] üß≠ Router analyzing question...")

    try:
        llm = OpenRouterLLM(state['model_name'])

        # Format chat history
        history_str = "\n".join([
            f"{msg['role']}: {msg['content']}"
            for msg in state.get('chat_history', [])[-3:]  # Last 3 messages
        ])

        prompt = f"""
Recent conversation:
{history_str if history_str else "None"}

Current question: {state['question']}

Classification:"""

        classification = llm.invoke(prompt, ROUTER_SYSTEM_PROMPT).strip().lower()

        # Extract just the classification word
        if "data" in classification:
            query_type = "data"
        elif "general" in classification:
            query_type = "general"
        else:
            query_type = "factual"

        print(f"[{state['model_name']}] ‚úÖ Classified as: {query_type}")

        return {"query_type": query_type}

    except Exception as e:
        print(f"[{state['model_name']}] ‚ùå Router error: {str(e)}")
        # Default to general conversation on error
        return {
            "query_type": "general",
            "error": f"Router error: {str(e)}"
        }


def sql_gen_node(state: AgentState) -> dict:
    """
    Node B: SQL Generator
    Generates SQL query based on the question
    """
    print(f"[{state['model_name']}] üîß Generating SQL query...")

    try:
        llm = OpenRouterLLM(state['model_name'])

        schema = get_database_schema()

        # Enhanced system prompt with schema
        system_prompt_with_schema = f"""{SQL_GENERATOR_SYSTEM_PROMPT}

DATABASE SCHEMA:
{schema}"""

        # Build prompt with error feedback if this is a retry
        if state.get('error') and state.get('retry_count', 0) > 0:
            prompt = f"""User question: {state['question']}

Previous SQL attempt: {state.get('sql_query')}
Error received: {state.get('error')}

Please fix the SQL query based on the error above.

SQL query:"""
        else:
            prompt = f"""User question: {state['question']}

SQL query:"""

        sql_query = llm.invoke(prompt, system_prompt_with_schema).strip()

        # Clean up the SQL (remove markdown if present)
        sql_query = sql_query.replace("```sql", "").replace("```", "").strip()
        # Remove any remaining backticks
        sql_query = sql_query.replace("`", "")

        print(f"[{state['model_name']}] üìù Generated SQL: {sql_query}")

        return {
            "sql_query": sql_query,
            "error": ""  # Clear previous errors
        }

    except Exception as e:
        print(f"[{state['model_name']}] ‚ùå SQL Generation error: {str(e)}")
        return {
            "error": f"SQL generation failed: {str(e)}",
            "retry_count": state.get('retry_count', 0) + 1
        }


def execute_sql_node(state: AgentState) -> dict:
    """
    Node C: Query DB
    Executes the SQL query and handles errors
    """
    print(f"[{state['model_name']}] üóÑÔ∏è  Executing SQL...")

    try:
        conn = sqlite3.connect("real_estate_data.db")
        cursor = conn.cursor()
        cursor.execute(state['sql_query'])
        results = cursor.fetchall()
        conn.close()

        sql_result = json.dumps(results)
        print(f"[{state['model_name']}] ‚úÖ Query successful: {len(results)} rows")

        return {
            "sql_result": sql_result,
            "error": "",
            "retry_count": 0
        }

    except Exception as e:
        error_msg = str(e)
        retry_count = state.get('retry_count', 0) + 1
        print(f"[{state['model_name']}] ‚ùå SQL Error (attempt {retry_count}): {error_msg}")

        return {
            "error": error_msg,
            "retry_count": retry_count
        }


def response_node(state: AgentState) -> dict:
    """
    Node D: Response Synthesizer
    Generates the final natural language response
    """
    print(f"[{state['model_name']}] üí¨ Generating final response...")

    try:
        # Check if there were persistent errors
        if state.get('error') and state.get('retry_count', 0) >= 2:
            # Maximum retries exceeded - provide user-friendly error message
            return {
                "final_answer": "I apologize, but I'm having trouble processing your data query at the moment. "
                               "This could be due to the complexity of the question or a temporary issue. "
                               "Please try rephrasing your question or try again in a moment."
            }

        llm = OpenRouterLLM(state['model_name'])

        if state['query_type'] == 'data':
            # Check if we have valid results
            if not state.get('sql_result'):
                return {
                    "final_answer": "I couldn't retrieve the data you requested. "
                                   "Please try rephrasing your question or ask something else."
                }

            prompt = f"""User question: {state['question']}

SQL Query executed: {state['sql_query']}
Results: {state['sql_result']}

Provide a clear, concise answer:"""

            final_answer = llm.invoke(prompt, RESPONSE_SYSTEM_PROMPT)

        else:
            # General or factual conversation
            final_answer = llm.invoke(state['question'], GENERAL_CONVERSATION_PROMPT)

        print(f"[{state['model_name']}] ‚úÖ Response generated")

        return {"final_answer": final_answer}

    except Exception as e:
        print(f"[{state['model_name']}] ‚ùå Response generation error: {str(e)}")
        # Fallback response for any errors
        return {
            "final_answer": "I apologize, but I'm unable to generate a response right now. "
                           "This might be a temporary issue. Please try again in a moment."
        }


# =======================
# 6. CONDITIONAL LOGIC
# =======================

def route_query(state: AgentState) -> Literal["sql_gen", "response", "end"]:
    """Determines where to go after the router"""
    if state['query_type'] == 'data':
        return "sql_gen"
    else:
        return "response"


def check_sql_error(state: AgentState) -> Literal["sql_gen", "response"]:
    """Determines if we need to retry SQL generation"""
    if state.get('error') and state.get('retry_count', 0) < 2:
        # Retry SQL generation (max 2 retries)
        return "sql_gen"
    else:
        return "response"


# =======================
# 7. GRAPH CONSTRUCTION
# =======================

def create_graph(model_name: str) -> StateGraph:
    """Creates the LangGraph workflow"""

    workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("router", router_node)
    workflow.add_node("sql_gen", sql_gen_node)
    workflow.add_node("execute_sql", execute_sql_node)
    workflow.add_node("response", response_node)

    # Set entry point
    workflow.set_entry_point("router")

    # Add conditional edge from router
    workflow.add_conditional_edges(
        "router",
        route_query,
        {
            "sql_gen": "sql_gen",
            "response": "response"
        }
    )

    # Add edge from SQL gen to execution
    workflow.add_edge("sql_gen", "execute_sql")

    # Add conditional edge for error handling (cyclic!)
    workflow.add_conditional_edges(
        "execute_sql",
        check_sql_error,
        {
            "sql_gen": "sql_gen",  # Retry SQL generation
            "response": "response"  # Move to response
        }
    )

    # Add edge from response to end
    workflow.add_edge("response", END)

    return workflow.compile()


# =======================
# 8. MODEL COMPARISON
# =======================

def compare_models(question: str, chat_history: List[dict] = None):
    """Compare responses from both models with error handling"""

    models = {
        "Qwen 2.5": "qwen/qwen-2.5-72b-instruct",
        "DeepSeek V3": "deepseek/deepseek-chat"
    }

    chat_history = chat_history or []

    print("\n" + "="*70)
    print(f"QUESTION: {question}")
    print("="*70 + "\n")

    results = {}

    for model_display_name, model_id in models.items():
        print(f"\n{'‚îÄ'*70}")
        print(f"ü§ñ Testing with {model_display_name}")
        print(f"{'‚îÄ'*70}\n")

        try:
            # Create graph for this model
            graph = create_graph(model_id)

            # Initial state
            initial_state = {
                "question": question,
                "chat_history": chat_history,
                "query_type": "",
                "sql_query": "",
                "sql_result": "",
                "final_answer": "",
                "error": "",
                "retry_count": 0,
                "model_name": model_id
            }

            # Run the graph
            final_state = graph.invoke(initial_state)

            results[model_display_name] = {
                "query_type": final_state['query_type'],
                "sql_query": final_state.get('sql_query', 'N/A'),
                "final_answer": final_state['final_answer'],
                "error": final_state.get('error', ''),
                "success": True
            }

            print(f"\n‚ú® {model_display_name} Response:")
            print(f"{final_state['final_answer']}\n")

        except Exception as e:
            error_msg = str(e)
            print(f"\n‚ùå {model_display_name} Error: {error_msg}\n")

            results[model_display_name] = {
                "query_type": "error",
                "sql_query": "N/A",
                "final_answer": f"Error: {error_msg}",
                "error": error_msg,
                "success": False
            }

    # Print comparison summary
    print("\n" + "="*70)
    print("üìä COMPARISON SUMMARY")
    print("="*70 + "\n")

    for model_name, result in results.items():
        status = "‚úÖ Success" if result.get('success') else "‚ùå Failed"
        print(f"{model_name}: {status}")
        print(f"  Query Type: {result['query_type']}")
        if result['query_type'] == 'data' and result.get('success'):
            print(f"  SQL: {result['sql_query']}")
        print(f"  Answer: {result['final_answer'][:100]}...")
        if result.get('error'):
            print(f"  Error: {result['error'][:100]}...")
        print()

    return results


# =======================
# 9. EXAMPLE USAGE
# =======================

if __name__ == "__main__":
    # Setup database
    print("üèóÔ∏è  Setting up Real Estate database...")
    schema = create_real_estate_db()
    print("‚úÖ Database ready!\n")

    # Test questions for real estate data
    test_questions = [
        "How many projects are under construction?",
        "Which projects have more than 75% open space?",
        "What is the cheapest 2BHK apartment available?",
        "Show me all 3BHK units with their prices",
        "Which units have festive offers right now?",
        "What is the average price per sqft for villas?",
        "List all projects by Prestige Group with their unit types",
        "Show me projects near the airport with pricing details"
    ]

    # Run comparison for each question
    for question in test_questions:
        compare_models(question)
        print("\n" + "="*70 + "\n")
