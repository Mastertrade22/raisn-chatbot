"""
Test script to verify the refactored code works correctly
Run this to ensure everything is set up properly
"""

import sys
from typing import Dict, Any


def test_imports() -> bool:
    """Test if all modules can be imported"""
    print("Testing imports...")

    try:
        import config
        print("  ‚úÖ config.py imported")
    except Exception as e:
        print(f"  ‚ùå config.py failed: {e}")
        return False

    try:
        import llm_client
        print("  ‚úÖ llm_client.py imported")
    except Exception as e:
        print(f"  ‚ùå llm_client.py failed: {e}")
        return False

    try:
        import database
        print("  ‚úÖ database.py imported")
    except Exception as e:
        print(f"  ‚ùå database.py failed: {e}")
        return False

    try:
        import chatbot_core
        print("  ‚úÖ chatbot_core.py imported")
    except Exception as e:
        print(f"  ‚ùå chatbot_core.py failed: {e}")
        return False

    print("‚úÖ All imports successful!\n")
    return True


def test_config() -> bool:
    """Test configuration module"""
    print("Testing configuration...")

    try:
        from config import (
            AVAILABLE_MODELS,
            OPENROUTER_API_KEY,
            DB_PATH,
            MAX_SQL_RETRIES,
            get_model_config
        )

        print(f"  ‚úÖ Available models: {list(AVAILABLE_MODELS.keys())}")
        print(f"  ‚úÖ Default retries: {MAX_SQL_RETRIES}")
        print(f"  ‚úÖ Database path: {DB_PATH}")

        if OPENROUTER_API_KEY:
            print("  ‚úÖ API key loaded")
        else:
            print("  ‚ö†Ô∏è  API key not found (set OPENROUTER_API_KEY in .env)")

        # Test get_model_config
        model_config = get_model_config("qwen")
        print(f"  ‚úÖ Model config works: {model_config['display_name']}")

        print("‚úÖ Configuration tests passed!\n")
        return True

    except Exception as e:
        print(f"  ‚ùå Configuration test failed: {e}\n")
        return False


def test_database() -> bool:
    """Test database module"""
    print("Testing database...")

    try:
        from database import db_interface, get_database_schema, execute_sql

        # Test connection
        if db_interface.test_connection():
            print("  ‚úÖ Database connection successful")
        else:
            print("  ‚ùå Database connection failed")
            return False

        # Test table counts
        counts = db_interface.get_table_counts()
        print(f"  ‚úÖ Projects: {counts.get('projects', 0)}")
        print(f"  ‚úÖ Units: {counts.get('project_units', 0)}")

        # Test schema retrieval
        schema = get_database_schema()
        if "projects" in schema and "project_units" in schema:
            print("  ‚úÖ Schema retrieved successfully")
        else:
            print("  ‚ùå Schema incomplete")
            return False

        # Test query execution
        results, error = execute_sql("SELECT COUNT(*) FROM projects")
        if error is None:
            print(f"  ‚úÖ Query execution works: {results[0][0]} projects")
        else:
            print(f"  ‚ùå Query execution failed: {error}")
            return False

        print("‚úÖ Database tests passed!\n")
        return True

    except Exception as e:
        print(f"  ‚ùå Database test failed: {e}\n")
        return False


def test_llm_client() -> bool:
    """Test LLM client module"""
    print("Testing LLM client...")

    try:
        from llm_client import create_llm_client
        from config import OPENROUTER_API_KEY, AVAILABLE_MODELS

        if not OPENROUTER_API_KEY:
            print("  ‚ö†Ô∏è  Skipping LLM test (no API key)")
            return True

        # Create client
        model_id = AVAILABLE_MODELS["qwen"]["id"]
        llm = create_llm_client(model_id)
        print(f"  ‚úÖ LLM client created for {model_id}")

        # Test invoke (simple prompt)
        try:
            response = llm.invoke("Say 'test successful' and nothing else.")
            if response:
                print(f"  ‚úÖ LLM invoke works: '{response[:50]}...'")
            else:
                print("  ‚ùå LLM returned empty response")
                return False
        except Exception as e:
            print(f"  ‚ö†Ô∏è  LLM invoke test skipped: {e}")
            # Don't fail the test - API key might have issues

        print("‚úÖ LLM client tests passed!\n")
        return True

    except Exception as e:
        print(f"  ‚ùå LLM client test failed: {e}\n")
        return False


def test_chatbot_core() -> bool:
    """Test chatbot core module"""
    print("Testing chatbot core...")

    try:
        from chatbot_core import create_chatbot
        from config import OPENROUTER_API_KEY

        # Create chatbot
        chatbot = create_chatbot()
        print("  ‚úÖ Chatbot created successfully")

        if not OPENROUTER_API_KEY:
            print("  ‚ö†Ô∏è  Skipping chatbot ask test (no API key)")
            return True

        # Test ask method
        try:
            response = chatbot.ask("Hello", preserve_history=False)
            print(f"  ‚úÖ Chatbot ask() works")
            print(f"     Query type: {response['query_type']}")
            print(f"     Has answer: {bool(response['final_answer'])}")

            # Test with data query
            response = chatbot.ask("How many projects are there?", preserve_history=False)
            print(f"  ‚úÖ Data query works")
            print(f"     Query type: {response['query_type']}")
            print(f"     SQL generated: {bool(response.get('sql_query'))}")

        except Exception as e:
            print(f"  ‚ö†Ô∏è  Chatbot ask test warning: {e}")
            # Don't fail - API might have issues

        # Test history methods
        chatbot.reset_history()
        print("  ‚úÖ History reset works")

        history = chatbot.get_history()
        print(f"  ‚úÖ Get history works: {len(history)} messages")

        print("‚úÖ Chatbot core tests passed!\n")
        return True

    except Exception as e:
        print(f"  ‚ùå Chatbot core test failed: {e}\n")
        return False


def run_all_tests() -> Dict[str, bool]:
    """Run all tests and return results"""
    print("="*70)
    print("REFACTORED CODE TEST SUITE")
    print("="*70)
    print()

    results = {
        "imports": test_imports(),
        "config": test_config(),
        "database": test_database(),
        "llm_client": test_llm_client(),
        "chatbot_core": test_chatbot_core()
    }

    return results


def print_summary(results: Dict[str, bool]) -> None:
    """Print test summary"""
    print("="*70)
    print("TEST SUMMARY")
    print("="*70)

    total = len(results)
    passed = sum(1 for v in results.values() if v)

    for test_name, passed_flag in results.items():
        status = "‚úÖ PASS" if passed_flag else "‚ùå FAIL"
        print(f"{status} - {test_name}")

    print()
    print(f"Results: {passed}/{total} tests passed")

    if passed == total:
        print("\nüéâ All tests passed! Your refactored code is ready to use.")
        print("\nNext steps:")
        print("  1. Run: python demo_cli.py")
        print("  2. Run: streamlit run streamlit_app_new.py")
        print("  3. Read: QUICKSTART_NEW.md")
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Please check the errors above.")
        print("Common issues:")
        print("  - Missing OPENROUTER_API_KEY in .env file")
        print("  - Missing dependencies (run: pip install -r requirements.txt)")
        print("  - Database permissions")


if __name__ == "__main__":
    try:
        results = run_all_tests()
        print_summary(results)

        # Exit with error code if any test failed
        if not all(results.values()):
            sys.exit(1)

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Tests interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Fatal error during testing: {e}")
        sys.exit(1)
